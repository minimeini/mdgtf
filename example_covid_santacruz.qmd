---
title: "Example - Covid Santa Cruz"
date: "`r Sys.Date()`"
author: "Meini Tang"
pdf-engine: pdflatex
format: 
  pdf:
    include-in-header:
      text: |
        \usepackage{geometry}
        \usepackage{booktabs}
        \usepackage{float}
        \usepackage{pdflscape}
        \usepackage{hhline}
    toc: true
    toc-depth: 2
    number-sections: true
    number-depth: 2
    fig-align: 'center'
    fig-pos: 'H'
    keep-tex: true
    tbl-cap-location: bottom
    layout-valign: bottom
error: true
---

Run `quarto render /Users/meinitang/Dropbox/Repository/poisson-dlm/example_covid_santacruz.qmd --to pdf` to compile.


```{r}
#| label: global argument
save_data <- TRUE
save_figures <- TRUE
plot_figures <- TRUE

tag <- "covid-santacruz"
Tag2 <- "Santa Cruz"

kstep_forecast_err <- 10
eval_forecast_err <- TRUE
eval_fitted_err <- TRUE

loss <- "quadratic"

fig_height <- 10.1
fig_width <- 13.8

fig_width_rect <- 11.5
fig_height_rect <- 4

param_list <- c("mu0", "rho", "W", "par1", "par2")
param_infer <- c("W")
```

```{r}
#| label: source code

library(ggplot2)
library(gridExtra)

repo <- "/Users/meinitang/Dropbox/Repository/poisson-dlm"
Rcpp::sourceCpp(file.path(repo, "export.cpp"))
source(file.path(repo, "plot_timeseries_creditble_interval.r"))
source(file.path(repo, "external_methods.r"))

dpath <- "/Users/meinitang/Dropbox/Research/Project1"
opath <- "/Users/meinitang/Dropbox/Research/Project1/real"
```


## Modal and Data


```{r}
#| label: santa cruz county data
#|

data <- read.csv(file.path(dpath, "county", "covid19cases_test.csv"))
data <- data[data$area == Tag2, ]
data$date <- as.Date(data$date)
data <- data[data$date >= "2020-03-01", ]
data <- data[1:(nrow(data) - 1), ]

y <- data$cases
n <- length(y)

data2 <- data[data$date >= "2020-07-01" & data$date < "2021-12-01", ]
ddate <- data2$date
y2 <- c(0, data2$cases)

y3 <- round(smooth.spline(y2, spar = 0.000001)$y)

p1 <- ggplot(
    data = data.frame(y = y2, t = 0:(length(y2) - 1)),
    aes(x = t, y = y)
) +
    geom_line() +
    theme_light() +
    xlab("Time t") +
    ylab("Observed Count Values y")


if (plot_figures) {
    plot(p1)
}
```

```{r}
#| label: save figure of y

if (save_figures) {
    ggsave(
        file.path(opath, paste0(tag, "-y.pdf")),
        plot = p1,
        device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )
}
```


```{r}
#| label: model

component <- list(
    obs_dist = "nbinom",
    link_func = "identity",
    trans_func = "sliding",
    gain_func = "softplus",
    lag_dist = "lognorm",
    err_dist = "gaussian"
)
param <- list(
    obs = c(1, 30),
    lag = c(1.386262, 0.3226017), # mode = 2.8969
    err = c(0.01, 0)
)
dim <- list(
    nlag = 16,
    ntime = length(y2) - 1,
    truncated = TRUE,
    regressor_baseline = FALSE
)

mod <- list(
    model = component,
    param = param,
    dim = dim
)

rm(dim)
rm(param)
rm(component)
```




## Algorithm Comparison

### Linear Bayes

#### Parameter Tuning

```{r}
#| label: lba tuning discount factor
#| include: false

opts.lba <- dgtf_default_algo_settings("lba")
opts.lba$W <- 0.01
opts.lba$use_discount <- TRUE
opts.lba$use_custom <- TRUE
opts.lba$num_step_ahead_forecast <- 10

opts.lba$use_discount <- TRUE
opts.lba$use_custom <- TRUE

delta.lba <- dgtf_tuning(
    mod, y2, "lba", opts.lba,
    "discount_factor",
    from = 0.8, to = 0.99, delta = 0.01,
    loss = "absolute"
)

p1 <- ggplot(
    data.frame(delta = delta.lba[, 1], error = delta.lba[, 2]),
    aes(x = delta, y = error)
) +
    geom_point() +
    theme_light() +
    geom_line(alpha = 0.7, color = "grey") +
    xlab("Discount Factor") +
    ylab("MFE") +
    theme(text = element_text(size = 16))

if (plot_figures) {
    plot(p1)
}
```


```{r}
#| label: lba tuning W
#| include: false

W_grid <- seq(from = 0.001, to = 0.04, by = 0.001)
opts.lba$use_discount <- FALSE

W.lba <- dgtf_tuning(
    mod, y2, "lba", opts.lba,
    "W",
    grid = W_grid,
    loss = "absolute"
)

p2 <- ggplot(
    data.frame(W = W.lba[, 1], error = W.lba[, 2]),
    aes(x = W, y = error)
) +
    geom_point() +
    theme_light() +
    geom_line(alpha = 0.7, color = "grey") +
    xlab("W") +
    ylab("MFE") +
    theme(text = element_text(size = 16))

if (plot_figures) {
    plot(p2)
}
```

```{r}
#| label: figure of lba tuning

if (save_figures) {
    ggsave(
        file.path(
            opath, "discount-factor",
            paste0(tag, "-lba-optimal-discount-factor.pdf")
        ),
        plot = p1, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )

    ggsave(
        file.path(opath, "W", paste0(tag, "-lba-optimal-W.pdf")),
        plot = p2, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )
}

```

#### Optimal Settings

```{r}
#| label: optimal settings of lba


opts.lba <- dgtf_default_algo_settings("lba")

opts.lba$W <- 0.005

opts.lba$use_discount <- TRUE
opts.lba$use_custom <- TRUE

opts.lba$discount_type <- "first_elem"
opts.lba$custom_discount_factor <- 0.91
```

#### Inference

```{r}
#| label: run dgtf_infer of lba with discount factor
#| include: false
opts.lba$use_discount <- TRUE
out.lba <- dgtf_infer(
    mod, y2,
    "lba", opts.lba,
    forecast_error = eval_forecast_err,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err,
    loss_func = loss
)

print(summary(c(out.lba$fit$mu0)))
```

```{r}
#| label: run dgtf_infer of lba with W
#| include: false

opts.lba$use_discount <- FALSE

out.lba2 <- dgtf_infer(
    mod, y2,
    "lba", opts.lba,
    forecast_error = eval_forecast_err,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err,
    loss_func = loss
)

```

```{r}
#| label: evaluation of lba
#| error: true
print(print_loss_all(out.lba))
print(print_loss_all(out.lba2))
```


```{r}
#| label: figure of lba inference
plots <- plot_output(
    out.lba, y2,
    save_figures = save_figures,
    tag = paste0(tag, "-lba-"), opath = opath,
    plot_figures = plot_figures
)

```

```{r}
#| label: save lba data

if (save_data) {
    save(
        out.lba, out.lba2, opts.lba, delta.lba, W.lba,
        file = file.path(
            opath, "data",
            paste0(tag, "-lba.RData")
        )
    )
}
```



### MCS

#### Parameter Tuning

```{r}
#| label: mcs tuning discount factor
#| include: false
#| eval: false

opts.mcs <- dgtf_default_algo_settings("mcs")
opts.mcs$num_backward <- 10
opts.mcs$num_particle <- 5000
opts.mcs$num_step_ahead_forecast <- 10

opts.mcs$W <- 0.01
opts.mcs$use_discount <- TRUE
opts.mcs$use_custom <- TRUE

delta.mcs <- dgtf_tuning(
    mod, y2, "mcs", opts.mcs,
    "discount_factor",
    from = 0.7, to = 1, delta = 0.01
)

p1 <- ggplot(
    data.frame(delta = delta.mcs[delta.mcs[, 1] >= 0.8, 1], error = delta.mcs[delta.mcs[, 1] >= 0.8, 2]),
    aes(x = delta, y = error)
) +
    geom_point() +
    theme_light() +
    geom_line(alpha = 0.7, color = "grey") +
    xlab("Discount Factor") +
    ylab("MFE") +
    theme(text = element_text(size = 16))

if (plot_figures) {
    plot(p1)
}
```


```{r}
#| label: mcs tuning W
#| include: false
#| eval: false

W_grid <- seq(from = 0.001, to = 0.03, by = 0.0005)
opts.mcs$use_discount <- FALSE

W.mcs <- dgtf_tuning(
    mod, y2, "mcs", opts.mcs,
    "W",
    grid = W_grid
)

p2 <- ggplot(
    data.frame(W = W.mcs[, 1], error = W.mcs[, 2], error2 = W.mcs[, 3]),
    aes(x = W, y = error)
) +
    geom_point() +
    theme_light() +
    geom_line(alpha = 0.7, color = "grey") +
    xlab("W") +
    ylab("MFE") +
    theme(text = element_text(size = 16))
# +
# geom_point(aes(x=W, y = error2), color = "maroon") +
# geom_line(aes(x=W, y = error2), alpha = 0.7, color = "salmon")

if (plot_figures) {
    plot(p2)
}
```


```{r}
#| label: mcs tuning B
#| include: false
#| eval: false

opts.mcs$use_discount <- TRUE
opts.mcs$use_custom <- TRUE
opts.mcs$custom_discount_factor <- 0.9

B.mcs <- dgtf_tuning(
    mod, y2, "mcs", opts.mcs,
    "num_backward",
    from = 1, to = 30, delta = 1
)

p3 <- ggplot(
    data.frame(B = B.mcs[, 1], error = B.mcs[, 2]),
    aes(x = B, y = error)
) +
    geom_point() +
    theme_light() +
    geom_line(alpha = 0.7, color = "grey") +
    xlab("B") +
    ylab("Mean One-step-ahead Forecasting Error")

if (plot_figures) {
    plot(p3)
}
```

```{r}
#| label: figure of mcs tuning
#| eval: false

if (save_figures) {
    ggsave(
        file.path(
            opath, "discount-factor",
            paste0(tag, "-mcs-optimal-discount-factor.pdf")
        ),
        plot = p1, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )

    ggsave(
        file.path(
            opath, "W",
            paste0(tag, "-mcs-optimal-W.pdf")
        ),
        plot = p2, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )

    ggsave(
        file.path(
            opath, "num-backward",
            paste0(tag, "-mcs-optimal-B.pdf")
        ),
        plot = p3, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )
}

```


#### Optimal Settings

```{r}
#| label: optimal settings of MCS

# mod$model$obs_dist = "poisson"

opts.mcs <- dgtf_default_algo_settings("mcs")
opts.mcs$num_particle <- 50000
opts.mcs$num_step_ahead_forecast <- 10

opts.mcs$W <- 0.004

opts.mcs$use_discount <- TRUE
opts.mcs$use_custom <- TRUE
opts.mcs$custom_discount_factor <- 0.91

opts.mcs$num_backward <- 10

opts.mcs$mu0 <- list(
    prior_name = "uniform",
    prior_param = c(0., min(100, quantile(c(y2), 0.25)))
)
```

#### Inference

```{r}
#| label: run dgtf_infer of mcs with discount factor
#| include: false

opts.mcs$use_discount <- TRUE
out.mcs <- dgtf_infer(
    mod, y2,
    "mcs", opts.mcs,
    forecast_error = eval_forecast_err,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err,
    loss_func = loss
)
```

```{r}
#| label: run dgtf_infer of mcs with W
#| include: false

opts.mcs$use_discount <- FALSE
out.mcs2 <- dgtf_infer(
    mod, y2,
    "mcs", opts.mcs,
    forecast_error = eval_forecast_err,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err,
    loss_func = loss
)
```


```{r}
#| label: evaluation of mcs

if (exists("out.mcs")) {
    print(print_loss_all(out.mcs))
}

if (exists("out.mcs2")) {
    print(print_loss_all(out.mcs2))
}

```


```{r}
#| label: figure of mcs inference

if (exists("out.mcs")) {
    plots <- plot_output(
        out.mcs, y2,
        save_figures = save_figures,
        tag = paste0(tag, "-mcs-"), opath = opath,
        plot_figures = plot_figures
    )
}

if (exists("out.mcs2")) {
    plots <- plot_output(
        out.mcs2, y2,
        save_figures = save_figures,
        tag = paste0(tag, "-mcs2-"), opath = opath,
        plot_figures = plot_figures
    )
}
```


```{r}
#| label: save mcs data

if (save_data) {
    if (exists("out.mcs") && exists("out.mcs2")) {
        save(
            out.mcs, out.mcs2, opts.mcs,
            # delta.mcs, W.mcs, B.mcs,
            file = file.path(
                opath, "data",
                paste0(tag, "-mcs.RData")
            )
        )
    } else if (exists("out.mcs")) {
        save(
            out.mcs, opts.mcs,
            # delta.mcs, W.mcs, B.mcs,
            file = file.path(
                opath, "data",
                paste0(tag, "-mcs.RData")
            )
        )
    } else if (exists("out.mcs2")) {
        save(
            out.mcs2, opts.mcs,
            # delta.mcs, W.mcs, B.mcs,
            file = file.path(
                opath, "data",
                paste0(tag, "-mcs.RData")
            )
        )
    }
}
```


### FFBS

#### Parameter Tuning

```{r}
#| label: ffbs tuning of discount factor
#| include: false
#| eval: false

opts.ffbs <- dgtf_default_algo_settings("ffbs")
opts.ffbs$num_particle <- 5000
opts.ffbs$num_smooth <- 1000
opts.ffbs$do_smoothing <- TRUE
opts.ffbs$num_step_ahead_forecast <- 10

opts.ffbs$W <- 0.01
opts.ffbs$use_discount <- TRUE
opts.ffbs$use_custom <- TRUE
opts.ffbs$custom_discount_factor <- 0.88

delta.ffbs <- dgtf_tuning(
    mod, y2, "ffbs", opts.ffbs,
    "discount_factor",
    from = 0.8, to = 1, delta = 0.01
)

p1 <- ggplot(
    data.frame(delta = delta.ffbs[delta.ffbs[, 1] > 0.79, 1], error = delta.ffbs[delta.ffbs[, 1] > 0.79, 2]),
    aes(x = delta, y = error)
) +
    geom_point() +
    theme_light() +
    geom_line(alpha = 0.7, color = "grey") +
    xlab("Discount Factor") +
    ylab("Mean One-step-ahead Forecasting Error") +
    theme(text = element_text(size = 16))

if (plot_figures) {
    plot(p1)
}

```

```{r}
#| label: ffbs tuning of W
#| include: false
#| eval: false


W_grid <- seq(from = 0.001, to = 0.04, by = 0.001)
opts.ffbs$use_discount <- FALSE

W.ffbs <- dgtf_tuning(
    mod, y2, "ffbs", opts.ffbs,
    "W",
    grid = W_grid
)

p2 <- ggplot(
    data.frame(W = W.ffbs[W.ffbs[, 1] < 0.01, 1], error = W.ffbs[W.ffbs[, 1] < 0.01, 2]),
    aes(x = W, y = error)
) +
    geom_point() +
    theme_light() +
    geom_line(alpha = 0.7, color = "grey") +
    xlab("W") +
    ylab("Mean One-step-ahead Forecasting Error")

if (plot_figures) {
    plot(p2)
}

```

```{r}
#| label: figure of ffbs tuning
#| eval: false

if (save_figures) {
    ggsave(
        file.path(
            opath, "discount-factor",
            paste0(tag, "-ffbs-optimal-discount-factor.pdf")
        ),
        plot = p1, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )

    ggsave(
        file.path(
            opath, "W",
            paste0(tag, "-ffbs-optimal-W.pdf")
        ),
        plot = p2, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )
}
```

#### Optimal Settings

```{r}
#| label: optimal settings of ffbs
#| eval: false


opts.ffbs <- dgtf_default_algo_settings("ffbs")
opts.ffbs$num_particle <- 50000
opts.ffbs$num_smooth <- 1000
opts.ffbs$do_smoothing <- TRUE

opts.ffbs$num_step_ahead_forecast <- 10

opts.ffbs$W <- 0.001

opts.ffbs$use_discount <- TRUE
opts.ffbs$use_custom <- TRUE
opts.ffbs$custom_discount_factor <- 0.95

opts.ffbs$mu0 <- list(
    prior_name = "uniform",
    prior_param = c(0., min(100, quantile(c(y2), 0.25)))
)
```

#### Inference

```{r}
#| label: run dgtf_infer with ffbs with discount factor
#| include: false
#| eval: false

opts.ffbs$use_discount <- TRUE
out.ffbs <- dgtf_infer(
    mod, y2,
    "ffbs", opts.ffbs,
    forecast_error = eval_forecast_err,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err,
    loss_func = loss
)
```


```{r}
#| label: run dgtf_infer with ffbs with W
#| include: false
#| eval: false

opts.ffbs$use_discount <- FALSE
out.ffbs2 <- dgtf_infer(
    mod, y2,
    "ffbs", opts.ffbs,
    forecast_error = eval_forecast_err,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err,
    loss_func = loss
)
```

```{r}
#| error: true
#| label: evaluation of ffbs
if (exists("out.ffbs")) {
    print(print_loss_all(out.ffbs))
}

if (exists("out.ffbs2")) {
    print(print_loss_all(out.ffbs2))
}
```


```{r}
#| label: figure of ffbs inference

if (exists("out.ffbs")) {
    plots <- plot_output(
        out.ffbs, y2,
        save_figures = save_figures,
        tag = paste0(tag, "-ffbs-"), opath = opath,
        plot_figures = plot_figures
    )
}


if (exists("out.ffbs2")) {
    plots <- plot_output(
        out.ffbs2, y2,
        save_figures = save_figures,
        tag = paste0(tag, "-ffbs2-"), opath = opath,
        plot_figures = plot_figures
    )
}
```


```{r}
#| label: save ffbs data

if (save_data) {
    if (exists("out.ffbs") & exists("out.ffbs2")) {
        save(
            out.ffbs, out.ffbs2, opts.ffbs, delta.ffbs, W.ffbs,
            file = file.path(
                opath, "data",
                paste0(tag, "-ffbs.RData")
            )
        )
    } else if (exists("out.ffbs")) {
        save(
            out.ffbs, delta.ffbs, W.ffbs,
            file = file.path(
                opath, "data",
                paste0(tag, "-ffbs.RData")
            )
        )
    } else if (exists("out.ffbs2")) {
        save(
            out.ffbs2, delta.ffbs, W.ffbs,
            file = file.path(
                opath, "data",
                paste0(tag, "-ffbs.RData")
            )
        )
    }
}
```


### Two-filter Smoothing

#### Optimal Settings

```{r}
#| label: optimal settings of tfs

opts.tfs <- dgtf_default_algo_settings("tfs")
opts.tfs$num_particle <- 5000
opts.tfs$num_smooth <- 1000
opts.tfs$do_smoothing <- TRUE
opts.tfs$do_backward <- TRUE

opts.tfs$num_step_ahead_forecast <- 10

opts.tfs$W <- list(
    init = mod$param$err[1],
    infer = "W" %in% param_infer
)
opts.tfs$mu0 <- list(
    init = mod$param$obs[1],
    infer = "mu0" %in% param_infer
)

opts.tfs$use_discount <- "W" %in% param_infer
opts.tfs$use_custom <- TRUE
opts.tfs$custom_discount_factor <- 0.91

```

#### Inference

```{r}
#| label: run dgtf_infer with tfs with discount factor
#| include: false
out.tfs <- dgtf_infer(
    mod, y3,
    "tfs", opts.tfs,
    forecast_error = eval_forecast_err,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err,
    loss_func = loss
)
```

```{r}
#| error: true
#| label: evaluation of tfs

if (exists("out.tfs")) {
    print(print_loss_all(out.tfs))
}

if (exists("out.tfs2")) {
    print(print_loss_all(out.tfs2))
}

```

```{r}
#| label: figure of tfs inference

if (exists("out.tfs")) {
    plots <- plot_output(
        out.tfs, y2,
        save_figures = save_figures,
        tag = paste0(tag, "-tfs-"), opath = opath,
        plot_figures = plot_figures
    )
}


if (exists("out.tfs2")) {
    plots <- plot_output(
        out.tfs2, y2,
        save_figures = save_figures,
        tag = paste0(tag, "-tfs2-"), opath = opath,
        plot_figures = plot_figures
    )
}



```


```{r}
#| label: save tfs data

if (save_data) {
    if (exists("out.tfs") & exists("out.tfs2")) {
        save(
            out.tfs, out.tfs2, opts.tfs,
            file = file.path(
                opath, "data",
                paste0(tag, "-tfs.RData")
            )
        )
    } else if (exists("out.tfs")) {
        save(
            out.tfs,
            file = file.path(
                opath, "data",
                paste0(tag, "-tfs.RData")
            )
        )
    } else if (exists("out.tfs2")) {
        save(
            out.tfs2,
            file = file.path(
                opath, "data",
                paste0(tag, "-tfs.RData")
            )
        )
    }
}
```

### Particle Learning

#### Inference

```{r}
#| label: run dgtf_infer with pl
#| include: false
opts.pl <- dgtf_default_algo_settings("pl")
opts.pl$num_particle <- 5000
opts.pl$num_smooth <- 1000
opts.pl$num_step_ahead_forecast <- 0
opts.pl$do_smoothing <- TRUE

opts.pl$max_iter <- 100

opts.pl$mu0 <- list(
    init = mod$param$obs[1],
    infer = "mu0" %in% param_infer,
    prior_name = "normal",
    prior_param = c(0, 10.)
)

opts.pl$mu0_init <- list(
    prior_name = "constant",
    prior_param = c(mod$param$obs[1], 10.)
)

opts.pl$W <- list(
    init = mod$param$err[1],
    infer = "W" %in% param_infer,
    prior_name = "invgamma",
    prior_param = c(1, 1)
)

opts.pl$W_init <- list(
    prior_name = "invgamma",
    prior_param = c(100, 1)
)

opts.pl$rho <- list(
    infer = "rho" %in% param_infer,
    init = mod$param$obs[2],
    mh_sd = 0.01,
    prior_name = "gaussian",
    prior_param = c(0., 100.)
)

opts.pl$par1 <- list(
    infer = "par1" %in% param_infer,
    init = mod$param$lag[1],
    mh_sd = 0.002,
    prior_name = "gaussian",
    prior_param = c(1, 1.)
)


opts.pl$par2 <- list(
    infer = "par2" %in% param_infer,
    init = mod$param$lag[2],
    mh_sd = 0.01,
    prior_name = "invgamma",
    prior_param = c(1, 1.)
)



out.pl <- dgtf_infer(
    mod, y3,
    "pl", opts.pl,
    forecast_error = eval_forecast_err,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err
)
```

```{r}
#| label: evaluation of pl
if (exists("out.pl")) {
    print(print_loss_all(out.pl))
}
```

```{r}
#| label: figure of pl inference

if (exists("out.pl")) {
    plots <- plot_output(
        out.pl, y2,
        save_figures = save_figures,
        tag = paste0(tag, "-pl-"), opath = opath,
        plot_figures = plot_figures
    )
}

```

```{r}
#| label: run dgtf_infer with tfs with W estimated by pl
#| include: false

mod2 <- mod
if ("rho" %in% param_infer) {
    mod2$param$obs[2] <- median(out.pl$fit$rho)
}

if ("par1" %in% param_infer || "par2" %in% param_infer) {
    mod2$param$lag[1] <- median(out.pl$fit$par1)
    mod2$param$lag[2] <- median(out.pl$fit$par2)
}

opts.tfs <- dgtf_default_algo_settings("tfs")
opts.tfs$num_particle <- 100000
opts.tfs$do_smoothing <- TRUE
opts.tfs$num_step_ahead_forecast <- 10
opts.tfs$use_discount <- FALSE

opts.tfs$W <- list(
    init = ifelse("W" %in% param_infer, median(c(out.pl$fit$W)), mod$param$err[1]),
    infer = FALSE
)


opts.tfs$mu0 <- list(
    init = ifelse("mu0" %in% param_infer, median(c(out.pl$fit$mu0)), mod$param$obs[1]),
    infer = FALSE
)


opts.tfs$do_smoothing <- TRUE
opts.tfs$use_discount <- FALSE
out.tfs3 <- dgtf_infer(
    mod2, y3,
    "tfs", opts.tfs,
    forecast_error = eval_forecast_err,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err,
    loss_func = loss
)


if (exists("out.tfs3")) {
    plots <- plot_output(
        out.tfs3, y2,
        save_figures = save_figures,
        tag = paste0(tag, "-pl-"), opath = opath,
        plot_figures = plot_figures
    )
}


```


```{r}
#| label: save pl data

if (save_data) {
    var_list <- c("out.pl", "out.tfs3", "opts.pl", "opts.tfs", "mod2")
    var_list <- var_list[sapply(var_list, exists)]
    save(list = var_list, file = file.path(
        opath, "data",
        paste0(tag, "-pl-W.RData")
    ))
}
```


### HVA

#### Parameter Tuning

```{r}
#| label: hva tuning of learning rate
#| eval: false
#| include: false

opts.hva <- dgtf_default_algo_settings("hva")
opts.hva$nsample <- 1000
opts.hva$nthin <- 2
opts.hva$nburnin <- 1000
opts.hva$num_step_ahead_forecast <- 10

opts.hva$smc$num_particle <- 100
opts.hva$smc$num_backward <- 10
opts.hva$smc$do_smoothing <- TRUE


opts.hva$W$init <- 0.01
opts.hva$W$infer <- TRUE

opts.hva$eps_step_size <- 1.e-5
opts.hva$k <- 1

lrate.hva <- dgtf_tuning(
    mod, y2, "hva", opts.hva,
    "learning_rate",
    from = 0.01, to = 0.1, delta = 0.01
)

p1 <- ggplot(
    data.frame(delta = lrate.hva[, 1], error = lrate.hva[, 2]),
    aes(x = delta, y = error)
) +
    geom_point() +
    theme_light() +
    geom_line(alpha = 0.7, color = "grey") +
    xlab("Learning Rate") +
    ylab("Mean One-step-ahead Forecasting Error")

if (plot_figures) {
    plot(p1)
}
```

```{r}
#| label: hva tuning of step size
#| eval: false
#| include: false

opts.hva$learning_rate <- 0.02

eps_grid <- c(1.e-6, 1.e-5, 1.e-3, 1.e-2)
eps.hva <- dgtf_tuning(
    mod, y2, "hva", opts.hva,
    "step_size",
    grid = eps_grid
)

p2 <- ggplot(
    data.frame(delta = eps.hva[, 1], error = eps.hva[, 2]),
    aes(x = delta, y = error)
) +
    geom_point() +
    theme_light() +
    geom_line(alpha = 0.7, color = "grey") +
    xlab("Step Size") +
    ylab("Mean One-step-ahead Forecasting Error")

if (plot_figures) {
    plot(p2)
}
```

```{r}
#| label: figure of hva tuning

if (save_figures && exists("lrate.hva") && exists("p1")) {
    ggsave(
        file.path(
            opath, "hva",
            paste0(tag, "-hva-optimal-learning-rate.pdf")
        ),
        plot = p1, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )
}

if (save_figures && exists("eps.hva") && exists("p1")) {
    ggsave(
        file.path(
            opath, "hva",
            paste0(tag, "-hva-step-size.pdf")
        ),
        plot = p2, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )
}
```

#### Optimal Settings

```{r}
#| label: optimal settings of hva
#| eval: true

opts.hva <- dgtf_default_algo_settings("hva")
opts.hva$nsample <- 5000
opts.hva$nthin <- 2
opts.hva$nburnin <- 5000
opts.hva$num_step_ahead_forecast <- 10
opts.hva$num_eval_forecast_error <- 10

opts.hva$smc$num_particle <- 100
opts.hva$smc$num_backward <- 10
opts.hva$smc$do_smoothing <- TRUE


opts.hva$learning_rate <- 0.02
opts.hva$eps_step_size <- 1.e-5
opts.hva$k <- length(param_infer)


opts.hva$mu0$init <- mod$param$obs[1]
opts.hva$mu0$infer <- "mu0" %in% param_infer


opts.hva$W <- list(
    infer = "W" %in% param_infer,
    init = mod$param$err[1],
    prior_name = "invgamma",
    prior_param = c(1, 1)
)

opts.hva$rho$init <- mod$param$obs[2]
opts.hva$rho$infer <- "rho" %in% param_infer

opts.hva$par1 <- list(
    infer = "par1" %in% param_infer,
    init = 2,
    prior_name = "gaussian",
    prior_param = c(0., 1.)
)

opts.hva$par2 <- list(
    infer = "par2" %in% param_infer,
    init = mod$param$lag[2],
    prior_name = "invgamma",
    prior_param = c(1, 1)
)
```

#### Inference

```{r}
#| label: run dgtf_infer with hva
#| eval: true
#| include: false

out.hva <- dgtf_infer(
    mod, y3,
    "hva", opts.hva,
    forecast_error = FALSE,
    fitted_error = eval_fitted_err,
    k = 0
)
```



```{r}
#| error: true
#| label: evaluation of hva

if (exists("out.hva")) {
    out.hva.loss_all <- print_loss_all(out.hva)
    print(out.hva.loss_all)
}

```


```{r}
#| label: figure of hva inference

if (exists("out.hva")) {
    plots <- plot_output(
        out.hva, y3,
        save_figures = save_figures, tag = paste0(tag, "-hva-"), opath = opath,
        plot_figures = plot_figures
    )
}

```

```{r}
#| label: save hva data
if (save_data) {
    var_list <- c(
        "out.hva", "out.hva2",
        "opts.hva", "opts.hva2",
        "out.hva.loss_all", "out.hva2.loss_all"
    )

    var_list <- var_list[sapply(var_list, exists)]
    save(list = var_list, file = file.path(
        opath, "data",
        paste0(tag, "-hva-", paste(param_infer, collapse = ""), ".RData")
    ))
}
```


### MCMC

#### Inference

```{r}
#| label: run dgtf_infer with mcmc
#| eval: true
#| include: false
opts.mcmc <- dgtf_default_algo_settings("mcmc")
opts.mcmc$nsample <- 2000
opts.mcmc$nthin <- 5
opts.mcmc$nburnin <- 50000
opts.mcmc$num_step_ahead_forecast <- 10

opts.mcmc$mh_sd <- 1
opts.mcmc$epsilon <- 0.005
opts.mcmc$L <- 10
opts.mcmc$m <- c(0.1, 0.1)

opts.mcmc$mu0$init <- mod$param$obs[1]
opts.mcmc$mu0$infer <- "mu0" %in% param_infer
opts.mcmc$mu0$mh_sd <- 1

opts.mcmc$W$init <- mod$param$err[1]
opts.mcmc$W$infer <- "W" %in% param_infer

opts.mcmc$rho$init <- mod$param$obs[2]
opts.mcmc$rho$infer <- "rho" %in% param_infer
opts.mcmc$rho$mh_sd <- 0.5

opts.mcmc$par1 <- list(
    infer = "par1" %in% param_infer,
    init = mod$param$lag[1],
    prior_name = "gaussian",
    prior_param = c(0., 1.),
    mh_sd = 0.1
)

opts.mcmc$par2 <- list(
    infer = "par2" %in% param_infer,
    init = mod$param$lag[2],
    prior_name = "invgamma",
    prior_param = c(1, 1),
    mh_sd = 0.1
)

out.mcmc <- dgtf_infer(
    mod, y3,
    "mcmc", opts.mcmc,
    forecast_error = FALSE,
    fitted_error = eval_fitted_err,
    k = kstep_forecast_err
)
```

```{r}
#| label: evaluation of mcmc

if (exists("out.mcmc")) {
    out.mcmc.loss_all <- print_loss_all(out.mcmc)
    print(out.mcmc.loss_all)
}

```


```{r}
#| label: figure of mcmc

if (exists("out.mcmc")) {
    plots <- plot_output(
        out.mcmc, y2,
        save_figures = save_figures,
        tag = paste0(tag, "-mcmc-"), opath = opath,
        plot_figures = plot_figures
    )
}
```


```{r}
#| label: save mcmc data
if (save_data && exists("out.mcmc")) {
    var_list <- c("out.mcmc", "opts.mcmc", "out.mcmc.loss_all")
    var_list <- var_list[sapply(var_list, exists)]
    save(list = var_list, file = file.path(
        opath, "data",
        paste0(tag, "-mcmc-", paste(param_infer, collapse = ""), "-y3.RData")
    ))
}
```



## Model Selection

### Optimal Observation Distribution

```{r}
#| label: optimal obs with lba
#| eval: false


mod$model$obs_dist <- "nbinom"
delta_grid <- 1:100
out.stats.obs <- dgtf_optimal_obs(mod, y2, "lba", opts.lba, delta_grid)

mod$model$obs_dist <- "poisson"
out.lba2 <- dgtf_infer(mod, y2, "lba", opts.lba)

ymin <- min(c(out.stats.obs[, 2], out.lba2$error$forecast$y_loss_all[1]))
ymax <- max(c(out.stats.obs[, 2], out.lba2$error$forecast$y_loss_all[1]))

out.stats.obs <- as.data.frame(out.stats.obs)
colnames(out.stats.obs) <- c("delta", "forecast-err", "fit-err")
p <- ggplot(out.stats.obs, aes(x = delta, y = `forecast-err`)) +
    geom_point() +
    theme_light() +
    geom_hline(aes(yintercept = out.lba2$error$forecast$y_loss_all[1]), color = "maroon") +
    ylab("RMSE of one-step-ahead forecasting") +
    xlab(expression(delta))

if (plot_figures) {
    plot(p)
}

if (save_figures) {
    ggsave(
        file.path(
            opath, "model-selection",
            paste0(tag, "-lba-optimal-obs.pdf")
        ),
        plot = p, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )
}
```

```{r}
#| label: optimal obs with mcs
#| eval: false
mod$model$obs_dist <- "nbinom"
delta_grid <- 1:100
out.stats.obs2 <- dgtf_optimal_obs(mod, y2, "mcs", opts.mcs, delta_grid)

mod$model$obs_dist <- "poisson"
out.mcs2 <- dgtf_infer(mod, y2, "mcs", opts.mcs)

ymin <- min(c(out.stats.obs2[, 2], out.mcs2$error$forecast$y_loss_all[1]))
ymax <- max(c(out.stats.obs2[, 2], out.mcs2$error$forecast$y_loss_all[1]))

out.stats.obs2 <- as.data.frame(out.stats.obs2)
colnames(out.stats.obs2) <- c("delta", "forecast-err", "fit-err")
p <- ggplot(out.stats.obs2, aes(x = delta, y = `forecast-err`)) +
    geom_point() +
    theme_light() +
    geom_hline(aes(yintercept = out.mcs2$error$forecast$y_loss_all[1]), color = "maroon") +
    ylab("RMSE of one-step-ahead forecasting") +
    xlab(expression(delta))

if (plot_figures) {
    plot(p)
}
```

```{r}
#| label: optimal obs
#| eval: false

mod$model$obs_dist <- "nbinom"
mod$param$obs[2] <- 50
```

### Optimal Lag Distribution

```{r}
#| label: lognormal lag dist with lba
#| eval: false

mod$model$lag_dist <- "lognorm"

mu_grid <- seq(from = 1, to = 3, by = 0.1)
sd2_grid <- seq(from = 0.1, to = 3, by = 0.1)
grids <- expand.grid(mu_grid, sd2_grid)
grids$mode <- exp(grids[, 1] - grids[, 2])
grids <- grids[grids$mode < 30, ]
mu_grid <- sort(unique(grids[, 1]))
sd2_grid <- sort(unique(grids[, 2]))

out.stats.lag.lognorm <- dgtf_optimal_lag(
    mod, y2, "lba", opts.lba,
    mu_grid, sd2_grid
)

out.stats.lag.lognorm <- out.stats.lag.lognorm[!apply(out.stats.lag.lognorm, 1, anyNA), ]
out.stats.lag.lognorm <- as.data.frame(out.stats.lag.lognorm)
colnames(out.stats.lag.lognorm) <- c("mu", "sd2", "mean", "var", "mode", "forecast", "fit")
out.stats.lag.lognorm$mode_int <- as.factor(round(out.stats.lag.lognorm$mode))

p0 <- ggplot(out.stats.lag.lognorm, aes(mu, sd2, fill = forecast)) +
    geom_raster(na.rm = TRUE) +
    theme_minimal() +
    theme(
        legend.position = "top",
        text = element_text(size = 20),
        legend.key.size = unit(0.5, "inches"),
        panel.spacing = unit(0, "inches")
    ) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0))

p <- ggplot(data = data.frame(
    mode = c(out.stats.lag.lognorm$mode_int),
    mfe = c(out.stats.lag.lognorm$forecast)
), aes(x = mode, y = mfe)) +
    theme_light() +
    geom_boxplot() +
    xlab("Mode") +
    ylab("RMSE of one-step-ahead forecasting")

if (plot_figures) {
    lattice::contourplot(forecast ~ mu * sd2, data = out.stats.lag.lognorm)

    plot(p0)
    plot(p)
}

if (save_figures) {
    ggsave(
        file.path(
            opath, "model-selection",
            paste0(tag, "-lag-lognorm.pdf")
        ),
        plot = p, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )

    ggsave(
        file.path(
            opath, "model-selection",
            paste0(tag, "-lag-lognorm-heatmap.pdf")
        ),
        plot = p0, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )
}
```

```{r}
#| label: optimal param for lognormal lags
#| eval: false

lognorm_param <- c(1.4, 0.1)
```


```{r}
#| label: nbinom lag dist with lba
#| eval: false

# mod$model$obs_dist = "poisson"
mod$model$lag_dist <- "nbinom"
mod$param$lag <- c(0.395, 6)
kappa_grid <- seq(from = 0.1, to = 0.9, by = 0.05)
r_grid <- seq(from = 1, to = 6, by = 1)

out.stats.lag.nbinom <- dgtf_optimal_lag(
    mod, y2, "lba", opts.lba,
    kappa_grid, r_grid
)

out.stats.lag.nbinom <- out.stats.lag.nbinom[!apply(out.stats.lag.nbinom, 1, anyNA), ]
out.stats.lag.nbinom <- as.data.frame(out.stats.lag.nbinom)
colnames(out.stats.lag.nbinom) <- c("kappa", "r", "mean", "var", "mode", "forecast", "fit")
out.stats.lag.nbinom$mode_int <- as.factor(round(out.stats.lag.nbinom$mode))


p0 <- ggplot(out.stats.lag.nbinom, aes(kappa, r, fill = forecast)) +
    geom_raster(na.rm = TRUE) +
    theme_minimal() +
    theme(
        legend.position = "top",
        text = element_text(size = 20),
        legend.key.size = unit(0.5, "inches"),
        panel.spacing = unit(0, "inches")
    ) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0))

p <- ggplot(data = data.frame(
    mode = c(out.stats.lag.nbinom$mode_int),
    mfe = c(out.stats.lag.nbinom$forecast)
), aes(x = mode, y = mfe)) +
    theme_light() +
    geom_boxplot() +
    xlab("Mode") +
    ylab("RMSE of one-step-ahead forecasting")

if (plot_figures) {
    lattice::contourplot(forecast ~ kappa * r, data = out.stats.lag.nbinom)

    plot(p0)
    plot(p)
}

if (save_figures) {
    ggsave(
        file.path(
            opath, "model-selection",
            paste0(tag, "-lag-nbinom.pdf")
        ),
        plot = p, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )

    ggsave(
        file.path(
            opath, "model-selection",
            paste0(tag, "-lag-nbinom-heatmap.pdf")
        ),
        plot = p0, device = "pdf", dpi = 300,
        height = fig_height, width = fig_width
    )
}
```

```{r}
#| eval: false

nbinom_param <- c(0.45, 6)
```

```{r}
#| label: save model selection
#| eval: false

if (save_data) {
    save(
        mod, y2,
        out.stats.obs,
        # out.stats.obs2,
        out.stats.lag.nbinom,
        out.stats.lag.lognorm,
        lognorm_param,
        nbinom_param,
        file = file.path(
            opath, "data",
            paste0(tag, ".RData")
        )
    )
}
```



## External Methods

```{r}
#| label: run external methods
si_para <- lognorm2serial(1.386262, 0.3226017)
out.epi <- epi_poisson(c(y2), si_para[1], si_para[2])
out.wt <- wt_poisson(c(y2), si_para[1], si_para[2])
```

```{r}
#| label: figure of external methods

if (exists("out.epi") && exists("out.wt")) {
    p1 <- plot_ts_ci_single(out.epi)
    p2 <- plot_ts_ci_single(out.wt)

    p3 <- plot_ts_ci_multi(list(
        LBA = log(exp(out.lba$fit$psi) + 1),
        # HVB = log(exp(out1.hva$fit$psi) + 1),
        FFBS = log(exp(out.ffbs$fit$psi) + 1),
        PL = log(exp(out.pl$fit$psi) + 1),
        MCS = log(exp(out.mcs$fit$psi) + 1),
        EpiEstim = out.epi,
        WT = out.wt
    ), legend.position = "top")

    if (plot_figures) {
        plot(p1)
        plot(p2)
        plot(p3)
    }
}
```

```{r}
#| label: k step forecast for EpiEstim
#| eval: true
#| include: false
forecast.epi <- external_forecast(
    mod, si_para, c(y2),
    mod$param$err[1],
    mod$param$obs[1],
    "EpiEstim",
    loss, kstep_forecast_err
)

if (save_data) {
    save(
        out.epi, forecast.epi,
        file = file.path(
            opath, "data",
            paste0(tag, "-epi.RData")
        )
    )
}
```

```{r}
#| label: k step forecast for WT
#| eval: true
#| include: false

forecast.wt <- external_forecast(
    mod, si_para, c(y2),
    mod$param$err[1],
    mod$param$obs[1],
    "WT",
    loss, kstep_forecast_err
)



if (save_data) {
    save(
        out.wt, forecast.wt,
        file = file.path(
            opath, "data",
            paste0(tag, "-wt.RData")
        )
    )
}
```


```{r}
#| label: figure of forcast comparison
if (exists("forecast.wt") && exists("forecast.epi")) {
    dat <- data.frame(
        LBA = out.lba$error$forecast$y_loss_all,
        MCS = out.mcs$error$forecast$y_loss_all,
        FFBS = out.ffbs$error$forecast$y_loss_all,
        PL = out.pl$error$forecast$y_loss_all,
        EPI = forecast.epi$y_loss_all,
        WT = forecast.wt$y_loss_all,
        k = c(1:kstep_forecast_err)
    )

    dat2 <- reshape2::melt(dat, id.vars = "k", value.name = "MFE", variable.name = "algo")

    p <- ggplot(dat2, aes(x = k, y = MFE, group = algo, color = algo)) +
        geom_line() +
        theme_light()

    if (plot_figures) {
        plot(p)
    }
}
```


## Forecasting and Fitting Error

```{r}
library(foreach)
library("Rcpp2doParallel")



tstart <- 30
tend <- 519 - 10


parallel::detectCores()
n.cores <- parallel::detectCores() - 1
my.cluster <- parallel::makeCluster(
    n.cores,
    type = "PSOCK"
)
doParallel::registerDoParallel(cl = my.cluster)
foreach::getDoParRegistered()


foreach(
    t = tstart:tend,
    .packages = c("Rcpp", "RcppArmadillo", "Rcpp2doParallel")
) %dopar% {
    save_data <- TRUE
    save_figures <- TRUE
    plot_figures <- TRUE

    tag <- "covid-santacruz"
    Tag2 <- "Santa Cruz"

    param_infer <- c("W")

    repo <- "/Users/meinitang/Dropbox/Repository/poisson-dlm"
    Rcpp::sourceCpp(file.path(repo, "export.cpp"))

    dpath <- "/Users/meinitang/Dropbox/Research/Project1"
    opath <- "/Users/meinitang/Dropbox/Research/Project1/real"

    data <- read.csv(file.path(dpath, "county", "covid19cases_test.csv"))
    data <- data[data$area == Tag2, ]
    data$date <- as.Date(data$date)
    data <- data[data$date >= "2020-03-01", ]
    data <- data[1:(nrow(data) - 1), ]

    y <- data$cases
    n <- length(y)

    data2 <- data[data$date >= "2020-07-01" & data$date < "2021-12-01", ]
    ddate <- data2$date
    y2 <- c(0, data2$cases)

    component <- list(
        obs_dist = "nbinom",
        link_func = "identity",
        trans_func = "sliding",
        gain_func = "softplus",
        lag_dist = "lognorm",
        err_dist = "gaussian"
    )
    param <- list(
        obs = c(1, 30),
        lag = c(1.386262, 0.3226017), # mode = 2.8969
        err = c(0.01, 0)
    )
    dim <- list(
        nlag = 16,
        ntime = length(y2[1:t]) - 1,
        truncated = TRUE,
        regressor_baseline = FALSE
    )

    mod <- list(
        model = component,
        param = param,
        dim = dim
    )

    opts.hva <- dgtf_default_algo_settings("hva")
    opts.hva$nsample <- 5000
    opts.hva$nthin <- 2
    opts.hva$nburnin <- 5000
    opts.hva$num_step_ahead_forecast <- 10
    opts.hva$num_eval_forecast_error <- 10

    opts.hva$smc$num_particle <- 100
    opts.hva$smc$num_backward <- 10
    opts.hva$smc$do_smoothing <- TRUE


    opts.hva$learning_rate <- 0.02
    opts.hva$eps_step_size <- 1.e-5
    opts.hva$k <- length(param_infer)


    opts.hva$mu0$init <- mod$param$obs[1]
    opts.hva$mu0$infer <- "mu0" %in% param_infer


    opts.hva$W <- list(
        infer = "W" %in% param_infer,
        init = mod$param$err[1],
        prior_name = "invgamma",
        prior_param = c(1, 1)
    )

    opts.hva$rho$init <- mod$param$obs[2]
    opts.hva$rho$infer <- "rho" %in% param_infer

    opts.hva$par1 <- list(
        infer = "par1" %in% param_infer,
        init = 2,
        prior_name = "gaussian",
        prior_param = c(0., 1.)
    )

    opts.hva$par2 <- list(
        infer = "par2" %in% param_infer,
        init = mod$param$lag[2],
        prior_name = "invgamma",
        prior_param = c(1, 1)
    )


    forecast.hva <- dgtf_infer(
        mod, y2[1:t],
        "hva", opts.hva,
        forecast_error = TRUE,
        fitted_error = TRUE,
        k = 10
    )

    if (exists("forecast.hva")) {
        save(forecast.hva, file = file.path(
            opath, "data",
            paste0(
                tag, "-hva-",
                paste(param_infer, collapse = ""),
                "-forecast", t,
                ".RData"
            )
        ))
    }
}

stopCluster(my.cluster)
```

```{r}
#| label: forecasting and fitting error of hva
#| include: false
#| eval: false

# opts.hva$nsample <- 10
# opts.hva$nthin <- 1
# opts.hva$nburnin <- 10
opts.hva$tstart_pct <- 0.9
opts.hva$num_eval_forecast_error <- mod$dim$ntime - kstep_forecast_err - mod$dim$ntime * opts.hva$tstart_pct + 1

out.hva <- dgtf_infer(
    mod, y2,
    "hva", opts.hva,
    forecast_error = TRUE,
    fitted_error = TRUE,
    k = kstep_forecast_err
)

# plots <- plot_output(
#     out.hva, y2,
#     save_figures = save_figures, tag = paste0(tag, "-hva-"), opath = opath,
#     plot_figures = plot_figures
# )


# out.hva2 <- dgtf_infer(
#     mod2, y2,
#     "hva", opts.hva2,
#     forecast_error = TRUE,
#     fitted_error = TRUE,
#     k = kstep_forecast_err
# )


# plots <- plot_output(
#     out.hva2, y2,
#     save_figures = save_figures, tag = paste0(tag, "-hva2-"), opath = opath,
#     plot_figures = plot_figures
# )

if (save_data) {
    var_list <- c("out.hva", "out.hva2", "opts.hva", "opts.hva2")
    var_list <- var_list[sapply(var_list, exists)]
    save(list = var_list, file = file.path(
        opath, "data",
        paste0(tag, "-hva-W-forecast.RData")
    ))
}
```



```{r}
#| label: forecasting and fitting error of mcmc
#| include: false
#| eval: false

opts.mcmc <- dgtf_default_algo_settings("mcmc")
opts.mcmc$nsample <- 5000
opts.mcmc$nthin <- 2
opts.mcmc$nburnin <- 5000
# opts.mcmc$nsample <- 10
# opts.mcmc$nthin <- 1
# opts.mcmc$nburnin <- 10
opts.mcmc$num_step_ahead_forecast <- 10

opts.mcmc$mh_sd <- 0.1


opts.mcmc$mu0$init <- mod$param$obs[1]
opts.mcmc$mu0$infer <- "mu0" %in% param_infer
opts.mcmc$mu0$mh_sd <- 1

opts.mcmc$W$init <- mod$param$err[1]
opts.mcmc$W$infer <- "W" %in% param_infer

opts.mcmc$rho$init <- mod$param$obs[2]
opts.mcmc$rho$infer <- "rho" %in% param_infer
opts.mcmc$rho$mh_sd <- 0.5

opts.mcmc$par1 <- list(
    infer = "par1" %in% param_infer,
    init = mod$param$lag[1],
    prior_name = "gaussian",
    prior_param = c(0., 1.),
    mh_sd = 0.1
)

opts.mcmc$par2 <- list(
    infer = "par2" %in% param_infer,
    init = mod$param$lag[2],
    prior_name = "invgamma",
    prior_param = c(1, 1),
    mh_sd = 0.1
)


out.mcmc <- dgtf_infer(
    mod, y2,
    "mcmc", opts.mcmc,
    forecast_error = TRUE,
    fitted_error = TRUE,
    k = kstep_forecast_err
)

plots <- plot_output(
    out.mcmc, sim1$y,
    save_figures = save_figures, tag = paste0(tag, "-mcmc-"), opath = opath,
    plot_figures = plot_figures
)

if (save_data) {
    save(
        out.mcmc, opts.mcmc,
        file = file.path(
            opath, "data",
            paste0(tag, "-mcmc-W-forecast.RData")
        )
    )
}
```


## Forecasting

```{r}
opts.mcmc <- dgtf_default_algo_settings("mcmc")
opts.mcmc$nsample <- 5000
opts.mcmc$nthin <- 5
opts.mcmc$nburnin <- 10000
opts.mcmc$num_step_ahead_forecast <- 10

opts.mcmc$mh_sd <- 0.1


opts.mcmc$mu0$init <- mod$param$obs[1]
opts.mcmc$mu0$infer <- "mu0" %in% param_infer
opts.mcmc$mu0$mh_sd <- 1

opts.mcmc$W$init <- mod$param$err[1]
opts.mcmc$W$infer <- "W" %in% param_infer

opts.mcmc$rho$init <- mod$param$obs[2]
opts.mcmc$rho$infer <- "rho" %in% param_infer
opts.mcmc$rho$mh_sd <- 0.5

opts.mcmc$par1 <- list(
    infer = "par1" %in% param_infer,
    init = mod$param$lag[1],
    prior_name = "gaussian",
    prior_param = c(0., 1.),
    mh_sd = 0.2
)

opts.mcmc$par2 <- list(
    infer = "par2" %in% param_infer,
    init = mod$param$lag[2],
    prior_name = "invgamma",
    prior_param = c(1, 1),
    mh_sd = 0.2
)

```

### Multi-step-ahead forecasting (bi-monthly)

```{r}
ddate0 <- c(
    "2020-09-01", "2020-11-01",
    "2021-01-01", "2021-03-01", "2021-05-01",
    "2021-07-01", "2021-09-01", "2021-11-01"
)

idx0 <- which(ddate %in% as.Date(ddate0))
ytrue <- y2[idx0]

kstep <- c(1:10)

ycast <- array(0, dim = c(length(idx0), length(kstep), opts.mcmc$nsample))

for (ik in 1:length(kstep)) {
    k <- kstep[ik]

    opts.mcmc$num_step_ahead_forecast <- k

    for (ii in 1:length(idx0)) {
        idx <- idx0[ii]

        ytrain <- y2[1:(idx - k)]
        mod$dim$ntime <- length(ytrain) - 1

        out.forecast <- dgtf_infer(
            mod, ytrain, "mcmc", opts.mcmc,
            forecast_error = FALSE,
            fitted_error = TRUE,
            k = k
        )

        ycast[ii, ik, ] <- out.forecast$pred$ypred[k, ]
    }
}
```


### Forecasting the waves

`second_wave` and `third_wave` is a vector of (start, peak, end) dates.

Two-weeks-ahead forecasting (`k = 14`)
One-week-ahead forecasting (`k = 7`)

```{r}
second_wave_date <- as.Date(c("2020-10-01", "2020-11-15", "2021-01-01"))
second_wave_idx <- which(ddate %in% second_wave_date) + 1
second_wave_ytrue <- y2[second_wave_idx]

kstep <- c(1:14)

second_wave_ycast <- array(0, dim = c(length(second_wave_idx), length(kstep), opts.mcmc$nsample))

for (ik in 1:length(kstep)) {
    k <- kstep[ik]

    opts.mcmc$num_step_ahead_forecast <- k

    for (ii in 1:length(second_wave_idx)) {
        idx <- second_wave_idx[ii]

        ytrain <- y2[1:(idx - k)]
        mod$dim$ntime <- length(ytrain) - 1

        out.forecast <- dgtf_infer(
            mod, ytrain, "mcmc", opts.mcmc,
            forecast_error = FALSE,
            fitted_error = TRUE,
            k = k
        )

        second_wave_ycast[ii, ik, ] <- out.forecast$pred$ypred[k, ]
    }
}
```

```{r}
third_wave_date <- as.Date(c("2021-06-01", "2021-07-10", "2021-08-15"))
third_wave_idx <- which(ddate %in% third_wave_date) + 1
third_wave_ytrue <- y2[third_wave_idx]

kstep <- c(1:14)

third_wave_ycast <- array(0, dim = c(length(third_wave_idx), length(kstep), opts.mcmc$nsample))

for (ik in 1:length(kstep)) {
    k <- kstep[ik]

    opts.mcmc$num_step_ahead_forecast <- k

    for (ii in 1:length(third_wave_idx)) {
        idx <- third_wave_idx[ii]

        ytrain <- y2[1:(idx - k)]
        mod$dim$ntime <- length(ytrain) - 1

        out.forecast <- dgtf_infer(
            mod, ytrain, "mcmc", opts.mcmc,
            forecast_error = FALSE,
            fitted_error = TRUE,
            k = k
        )

        third_wave_ycast[ii, ik, ] <- out.forecast$pred$ypred[k, ]
    }
}
```


### Policy related scenes

2020-03-04 State of emergency declared.
2020-03-12 Social gatherings banned.
2020-03-19 California state-wide stay-at-home order issued.

2020-05-07 State 2 reopening
**2020-06-18 The Governor of California issued a mandate requiring residents to wear face coverings in common and public indoor spaces and outdoors when physical distancing is not possible.**


2020-07-14 CDC again calls on all people to wear cloth face masks.
**2020-12-14 Beginning of COVID-19 vaccination program.**
2020-12-17 Regional stay-at-home order went into effect for the Bay Area region.
2020-12-24 More than 1 million COVID-19 vaccine doses have been administered in the U.S. in just 10 days.

2020-01-25 Regional stay-at-home order lifted.

2021-02-02 CDC requires face masks to be worn by all travelers while on public transportation and inside transportation hubs.

By April 7 2021, the Alpha variant had become the dominant COVID-19 strain in the U.S.[132] On April 12, the U.S. reported its first cases of a new "double mutant" SARS-CoV-2 variant from India, later called Delta, in California.

**2021-04-21 More than 200 million COVID-19 vaccine doses have been administered in the U.S.**
April 2021 California mask mandate for vaccinated people lifted.

2021-05-13 CDC changed its guidance and said that fully vaccinated individuals do not need to wear masks in most situations.

**2021-06-15 California fully reopen.**

2021-11-19 Concerns of Omicron variant.
2021-12-01 The first case of Omicron variant in the US is detected by the California and San Francisco Departments of Public Health.

|             | Initial       | 2020-09-08 | 2020-10-13 | 2020-10-27 | 2020-11-10 | 2020-11-16    | 2021-03-02 | 2021-03-09 | 2021-03-16    |  
| ----------- | ------------- | ---------- | ---------- | ---------- | ---------- | ------------- | ---------- | ---------- | ------------- |
| Widespread  | SCL, SCZ, MON | MON        | MON        | MON        | MON        | SCL, SCZ, MON | SCZ, MON   | MON        |
| Substantial |               | SCL, SCZ   | SCZ        |            | SCZ        |               | SCL        | SCL, SCZ   | SCL, SCZ, MON | 
| Moderate    |               |            | SCL        | SCL, SCZ   | SCL        |               |
| Minimal     |               |            |            |            |            |               |

2021-03-02 Santa Clara is reassigned to Moderate.
2021-03-30 Santa Cruz is reassigned to Moderate.
2021-04-06 Monterey is reassigned to Moderate.
2021-05-18 Santa Cruz and Santa Clara is reassigned to Minimal.
2021-06-01 Monterey is reassigned to Minimal.

```{r}
key_date <- as.Date(c("2020-06-18", "2020-12-14", "2021-04-21", "2021-06-15"))
key_idx <- which(ddate %in% key_date) + 1

kstep <- c(1:14)
key_ycast <- array(0, dim = c(length(key_idx), length(kstep), opts.mcmc$nsample))
key_ytrue <- matrix(0, nrow = length(key_idx), ncol = length(kstep))

for (ii in 1:length(key_idx)) {
    idx <- key_idx[ii]
    ytrain <- y2[1:idx]
    mod$dim$ntime <- length(ytrain) - 1

    key_ytrue[ii, ] <- y2[idx + kstep]

    for (ik in 1:length(kstep)) {
        k <- kstep[ik]
        opts.mcmc$num_step_ahead_forecast <- k

        out.forecast <- dgtf_infer(
            mod, ytrain, "mcmc", opts.mcmc,
            forecast_error = FALSE,
            fitted_error = TRUE,
            k = k
        )

        key_ycast[ii, ik, ] <- out.forecast$pred$ypred[k, ]
    }
}
```