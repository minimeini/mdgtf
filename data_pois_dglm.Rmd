---
title: "Pois DGLM on Country- and County-Level Covid Data"
author: "Meini Tang"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    number_sections: true
    toc_depth: 2
    extra_dependencies: "subfig"
bibliography: references.bib
---


```{r, echo=FALSE}
knitr::opts_chunk$set(echo=FALSE, # show the code or not
                      highlight=FALSE,
                      tidy=FALSE,
                      include=TRUE, # include the output or not
                      results = FALSE,
                      fig.show="asis",
                      warning=FALSE,
                      message=FALSE,
                      error=FALSE,
                      fig.align='center',
                      out.width="50%")
rm(list=ls())
library(Rcpp)
library(ggplot2) 
library(gridExtra)
```

```{r}
sourceCpp("/Users/meinitang/Repository/pois_dglm_inference/lbe_poisson.cpp")
sourceCpp("/Users/meinitang/Repository/pois_dglm_inference/mcmc_disturbance_poisson.cpp")
source("/Users/meinitang/Repository/pois_dglm_inference/lbe_pois_utils.R")
```

```{r}
source("/Volumes/GoogleDrive/My Drive/Study_Resources/PhD/Research/Project1/hawkes_state_space.R")
```

```{r}
source("/Users/meinitang/Repository/pois_dglm_inference/lbe_pois_dlm.R")
```

```{r}
start_date = "2020-03-01"
end_date = "2021-03-1"
m0 = rep(0,3)
C0 = diag(rep(1,3))
```

# Models

The instantaneous occurrence rate of the continuous-time Hawkes process is
$$
\lambda(t) = \mu + R\sum_{t_k<t}\phi(t-t_l),
$$

where $\phi$ is the kernel representing the distribution of the transmission delays and $R$ is the reproduction number representing the average number of events induced by a single event. @Koyama_2021 convert it to a discrete-time Hawkes process,

$$
\lambda_t = \mu' + \sum_{k=1}^{t-1} \phi_k R_{t-k} y_{t-k},
$$

where $\mu'$ is the deterministic immigration intensity (which is assumed to be zero for now), $\phi_k$ measures the transmission delays at lag $k$, $R_t$ is the reproduction number.

We are comparing four models here. The first one is from @Koyama_2021:

$$
\mathcal{M}_1:
\begin{cases}
y_t | \lambda_t \sim \text{Pois}(\lambda_t)\\
\lambda_t := F_t(\theta_t) = \phi_1 y_{t-1}\max(\theta_{t-1},0) + \dots + \phi_L y_{t-L}\max(\theta_{t-L},0)\\
\theta_t = \theta_{t-1} + \omega_t,
\end{cases}
$$
where $\omega_t$ follows either a Cauchy distribution or normal distribution. Koyama et al. propose to use $\max(\theta_{t-1},0)$ as an estimator of the reproduction number $R_t$. The transmission delays ${\phi_1,\dots,\phi_L}$ are modeled by the PMF of a lognormal distribution with mean equal to 4.7 days and standard deviation equal to 2.9 days, which is the estimated distribution of the serial intervals [@Nishiura2020].


The second one is a modified version of $\mathcal{M}_2$, where $\max(\theta_{t-k},0)$ is substituted with $\exp(\theta_{t-k})$.

$$
\mathcal{M}_2:
\begin{cases}
y_t | \lambda_t \sim \text{Pois}(\lambda_t)\\
\lambda_t := F_t(\theta_t) = \phi_1 y_{t-1}\exp(\theta_{t-1}) + \dots + \phi_L y_{t-L}\exp(\theta_{t-L})\\
\theta_t = \theta_{t-1} + \omega_t,
\end{cases}
$$
where $\omega_t$ follows a normal distribution at this moment. It can also be extended to other error distributions. $\exp(\theta_{t-1})$ might be related to the reproduction number $R_t$.

For $\mathcal{M}_1$ and $\mathcal{M}_2$, the state space form is
$$
\begin{pmatrix}
\theta_{t}\\
\theta_{t-1}\\
\vdots\\
\theta_{t-L+1}
\end{pmatrix}
= 
\begin{pmatrix}
1 & \dots & 0 & 0\\
1 & \dots & 0 & 0\\
\vdots & \ddots & \vdots & \vdots\\
0 & \dots & 1 & 0
\end{pmatrix}
\begin{pmatrix}
\theta_{t-1}\\
\theta_{t-2}\\
\vdots\\
\theta_{t-L}
\end{pmatrix} +
\begin{pmatrix}
\omega_t\\
0\\
\vdots\\
0
\end{pmatrix}.
$$


The third model uses the Pascal distributed lags proposed by @Solow1960, with more discussion by @Ravines2006.

$$
\mathcal{M}_3:
\begin{cases}
y_t | \lambda_t \sim \text{Pois}(\lambda_t)\\
\lambda_t = \exp(\theta_t) \\
\theta_t = 2\rho\theta_{t-1} -\rho^2\theta_{t-2} + (1-\rho)^2\beta_t\log(y_{t-1})\\
\beta_t = \beta_{t-1} + \omega_t,
\end{cases}
$$

$\mathcal{M}_3$ doesn't really have a discretized Hawkes process form but the $\beta_t$ might be interesting.

The county-level data has many zero observations, which cause a trouble for $\mathcal{M}_3$. In this cases, $\beta_t$ will go to negative values, especially when the preceding number of daily new cases is non-zero. 

Model 4 is a variant of $\mathcal{M}_3$ using the identity link instead of the logarithm link.

$$
\mathcal{M}_4:
\begin{cases}
y_t | \lambda_t \sim \text{Pois}(\lambda_t)\\
\lambda_t = \theta_t \\
\theta_t = 2\rho\theta_{t-1} -\rho^2\theta_{t-2} + (1-\rho)^2\beta_ty_{t-1}\\
\beta_t = \beta_{t-1} + \omega_t,
\end{cases}
$$

It is also related to the discretized Hawkes process if we rewrite the evolution equations in the following way:

$$
\begin{aligned}
\theta_t &= \sum_{k=0}^{\infty} (k+1)(1-\rho)^2\rho^k\beta_t y_{t-k-1},\\
\beta_t &= \beta_{t-1} + \omega_t.
\end{aligned}
$$

The $\beta_t$ is the reproduction-ish number that could be interesting. There is no restriction on the parameter space of $\beta_t$ for now but we might want it to be positive.

The transmission delay $\phi_k=(k+1)(1-\rho)^2\rho^k$ is the PMF of a negative binomial distribution with mean equal to $2\rho/(1-\rho)$ and variance equal to $2\rho/(1-\rho)^2$, where $\rho$ is the success probability in each trial and the number of failures $r=2$. When $r=6$ and $\rho\approx 0.4393$, it has a mean equal to 4.7 and variance equal to 8.38 (standard deviation equal to 2.9), as suggested by @Nishiura2020. 

For now I just try $r=2$ and $\rho$ around 0.7, but the derivation should be similar for $r=6$. The comparisions of different PMF is shown in figure 1.

```{r,fig.cap="PMF of a LN(mu=1.39,sd=0.57) is the transmission delay used in Koyama et al. (2021), shown in green; NB(r=6,p=0.44) is the closest approximation of it, shown in red; NB(r=2,p=0.7) is the  transmission delay used in the following examples, shown in blue."}
r = 6
p = 4.7 / (4.7+r)

pk.mu = log(m/sqrt(1+(s/m)^2))
pk.sg2 = log(1+(s/m)^2)

tmp = data.frame(nb1=rnbinom(10000,r,1-p),
                 ln1=exp(rnorm(10000,mean=pk.mu,sd=sqrt(pk.sg2))),
                 nb2=rnbinom(10000,2,1-0.7))
colnames(tmp) = c("NB(r=6,p=0.44)","LN(mu=1.39,sd=0.57)","NB(r=2,p=0.7)")
tmp = reshape2::melt(tmp)
ggplot(tmp,aes(x=value,group=variable,fill=variable,color=variable)) +
  geom_histogram(position="identity",alpha=0.3,bins=100) +
  theme_bw() + theme(legend.position="bottom")
```




The state space form is 
$$
\begin{pmatrix}
\theta_t\\
\theta_{t-1}\\
\beta_t
\end{pmatrix}
=
\begin{pmatrix}
2\rho & -\rho^2 & (\rho)^2 x_t\\
1     & 0       & 0\\
0     & 0       & 1
\end{pmatrix}
\begin{pmatrix}
\theta_{t-1}\\
\theta_{t-2}\\
\beta_{t-1}
\end{pmatrix} +
\begin{pmatrix}
(1-\rho)^2 x_t \omega_t\\
0\\
\omega_t
\end{pmatrix}
$$


In the following examples, $\mathcal{M}_1$ is estimated by particle filtering assuming normal error terms, others are estimated by the linear Bayes estimator. $\beta_t$ might be related to the reproduction number $R_t$. Also, though I use the data from March 2020 to March 2021 to fit the models, I zoom into the period from May 2020 to March 2021 for visualization because the first few starting points sometimes goes wild for filtering.

\newpage


# Country-level Covid Data

Country-level Covid data from March 1, 2020 to March 1, 2021.

```{r}
data = read.csv("/Volumes/GoogleDrive/My Drive/Data/covid.csv")
data = data.frame(location=data$location,date=data$date, cases=data$new_cases)

cntry = c("Italy","Japan","Saudi Arabia","United States")
data = data[data$location%in%cntry,]
data$date = as.Date(data$date)
idx = (data$date >= start_date) & (data$date <= end_date)
data = data[idx,]
```

## US

```{r,out.width="50%"}
data_us = data[data$location=="United States",c(2,3)]
plot(data_us$date,data_us$cases,type="l",
     main="US",xlab="Date", ylab="Daily New Cases")
y = data_us$cases
n = length(y)
```

<!-- ### Koyama with Cauchy error -->

```{r,include=FALSE}
rate = hawke_ss2(y,rho=calc_rho(y),errtype="cauchy")
plot_hawkes_ss(y,rate$R,rate$itvl,rate$rate,
               x=data_us$date,
               plot_r=TRUE,plot_rate=FALSE)
```


<!-- ### Koyama with normal error -->

```{r,include=FALSE}
output1 = hawke_ss2(y,rho=calc_rho(y),errtype="normal")
plot_hawkes_ss(y,output1$R,output1$itvl,output1$rate,
               x = data_us$date,
               plot_r=TRUE,plot_rate=FALSE)
```


<!-- ### Koyama with exponential on reproduction number -->

```{r,include=FALSE}
output2 = lbe_pois_dlm(y,delta=0.99,L=30)
ts = 0
tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")
```



<!-- ### Pascal - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.7
output3 = lbe_poissonSolow(y[-1],log(y[-n]),rho,delta,m0,C0)
ts = 0
tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=c(output3$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output3$mt[1,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output3$mt[1,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])))

ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")


tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 beta=c(output3$mt[3,-c(1:(ts+1))]),
                 beta_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 beta_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))

ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=beta_lo,ymax=beta_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=beta),color="royalblue",na.rm=TRUE) +
  theme_bw() +
  xlab("Time") + ylab("Beta") + ylim(0.5,2)

# vest = diff(output$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```

<!-- ### Pascal Identity Link - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.8
output4 = lbe_poissonSolowIdentity(y[-1],y[-n],rho,delta,m0,C0)

ts = 50

tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=c(output4$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[1,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[1,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")

tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")

plot(data_us$date,y,type="l")

# vest = diff(output3$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```

### Compare three different models

```{r,fig.nrow=1,fig.subcap=c("M1 - KoyamaMax","M2 - KoyamaExp","M3 - PascalLog","M4 - PascalEye"),out.width="25%",fig.cap="US: M2 uses a discount factor equal of 0.99; M3 uses rho=0.7 and a discount factor of 0.7; M4 uses rho=0.7 and a discount factor of 0.8."}
ts = 50

plot_hawkes_ss(y[(ts+1):n],
               output1$R[(ts+1):(n-1)],
               output1$itvl[,(ts+1):(n-1)],
               output1$rate[(ts+1):n],
               x = data_us$date[(ts+1):n],
               plot_r=TRUE,plot_rate=FALSE)

tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("R")


tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 beta=c(output3$mt[3,-c(1:(ts+1))]),
                 beta_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 beta_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))

ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=beta_lo,ymax=beta_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=beta),color="royalblue",na.rm=TRUE) +
  theme_bw() +
  xlab("Time") + ylab("Beta") + ylim(0.5,2)


tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")
```


```{r,out.width="75%",fig.cap="US: M2 uses a discount factor equal of 0.99; M3 uses rho=0.7 and a discount factor of 0.7; M4 uses rho=0.7 and a discount factor of 0.8."}
ts = 50
tmp = data.frame(M1_KoyamaMax = output1$R[ts:(n-1)],
                 M2_KoyamaExp = exp(output2$mt_smooth[(1+ts):n,1]),
                 M3_PascalLog = output3$mt[3,(1+ts):(n)],
                 M4_PascalEye = output4$mt[3,(1+ts):(n)],
                 time = data_us$date[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p1 = ggplot(tmp,aes(x=time,y=value,color=variable)) +
  geom_line(show.legend=FALSE) + theme_bw() + 
  ylab("R") +
  theme(legend.position="none")

tmp = data.frame(M1_KoyamaMax = output1$rate[(1+ts):n],
                 M2_KoyamaExp = output2$rate[(1+ts):n],
                 M3_PascalLog = exp(output3$mt[1,(1+ts):n]),
                 M4_PascalEye = output4$mt[1,(1+ts):n],
                 time = data_us$date[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p2 = ggplot(tmp,aes(x=time)) +
  geom_point(aes(x=time,y=y),alpha=0.5,size=0.5,
             data=data.frame(time=data_us$date[(1+ts):n],y=y[(1+ts):n])) +
  geom_line(aes(y=value,color=variable),data=tmp) + theme_bw() + 
  ylab("Instantaneous Rate") +
  theme(legend.position="bottom")

grid.arrange(p1,p2,ncol=1)
```




\newpage

## Japan

```{r,out.width="50%"}
data_us = data[data$location=="Japan",c(2,3)]
plot(data_us$date,data_us$cases,type="l")
y = data_us$cases
n = length(y)
```

<!-- ### Koyama with Cauchy error -->

```{r,include=FALSE}
rate = hawke_ss2(y,rho=calc_rho(y),errtype="cauchy")
plot_hawkes_ss(y,rate$R,rate$itvl,rate$rate,
               x=data_us$date,
               plot_r=TRUE,plot_rate=FALSE)
```


<!-- ### Koyama with normal error -->

```{r,include=FALSE}
output1 = hawke_ss2(y,rho=calc_rho(y),errtype="normal")
plot_hawkes_ss(y,output1$R,output1$itvl,output1$rate,
               x = data_us$date,
               plot_r=TRUE,plot_rate=FALSE)
```

<!-- ### Koyama with exponential on reproduction number -->

```{r,include=FALSE}
output2 = lbe_pois_dlm(y,delta=0.99,L=30)
ts = 0
tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")
```

<!-- ### Pascal - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.9
output3 = lbe_poissonSolow(y[-1],log(y[-n]),rho,delta,m0,C0)
ts = 0
tmp = data.frame(time=data$date[(ts+1):(n-1)],
                 mt=c(output3$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output3$mt[1,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output3$mt[1,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])))

ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")


tmp = data.frame(time=data$date[(ts+1):(n-1)],
                 beta=c(output3$mt[3,-c(1:(ts+1))]),
                 beta_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 beta_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))

ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=beta_lo,ymax=beta_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=beta),color="royalblue") +
  theme_bw() + ylim(0,2) +
  xlab("Time") + ylab("Beta")

# vest = diff(output3$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```

<!-- ### Pascal Identity Link - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.8
output4 = lbe_poissonSolowIdentity(y[-1],y[-n],rho,delta,m0,C0)

ts = 50

tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=c(output4$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[1,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[1,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")

tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")

plot(data_us$date,y,type="l")

# vest = diff(output3$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```

### Compare three different models

```{r,fig.nrow=2,fig.subcap=c("M1-KoyamaMax","M2-KoyamaExp","M3-PascalLog","M4-PascalEye"),out.width="25%",fig.cap="Japan: M2 uses a discount factor equal of 0.99; M3 uses rho=0.7 and a discount factor of 0.8; M4 uses rho=0.7 and a discount factor of 0.9."}
ts = 50

plot_hawkes_ss(y[(ts+1):n],
               output1$R[(ts+1):(n-1)],
               output1$itvl[,(ts+1):(n-1)],
               output1$rate[(ts+1):n],
               x = data_us$date[(ts+1):n],
               plot_r=TRUE,plot_rate=FALSE)

tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("R")


tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 beta=c(output3$mt[3,-c(1:(ts+1))]),
                 beta_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 beta_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))

ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=beta_lo,ymax=beta_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=beta),color="royalblue",na.rm=TRUE) +
  theme_bw() +
  xlab("Time") + ylab("Beta") + ylim(0.5,2)


tmp = data.frame(time=data_us$date[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")
```

```{r,out.width="75%",fig.cap="Japan: M2 uses a discount factor equal of 0.99; M3 uses rho=0.7 and a discount factor of 0.8; M4 uses rho=0.7 and a discount factor of 0.9."}
ts = 50
tmp = data.frame(M1_KoyamaMax = output1$R[ts:(n-1)],
                 M2_KoyamaExp = exp(output2$mt_smooth[(1+ts):n,1]),
                 M3_PascalLog = output3$mt[3,(1+ts):(n)],
                 M4_PascalEye = output4$mt[3,(1+ts):(n)],
                 time = data_us$date[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p1 = ggplot(tmp,aes(x=time,y=value,color=variable)) +
  geom_line(show.legend=FALSE) + theme_bw() + 
  ylab("R") +
  theme(legend.position="none")

tmp = data.frame(M1_KoyamaMax = output1$rate[(1+ts):n],
                 M2_KoyamaExp = output2$rate[(1+ts):n],
                 M3_PascalLog = exp(output3$mt[1,(1+ts):n]),
                 M4_PascalEye = output4$mt[1,(1+ts):n],
                 time = data_us$date[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p2 = ggplot(tmp,aes(x=time)) +
  geom_point(aes(x=time,y=y),alpha=0.5,size=0.5,
             data=data.frame(time=data_us$date[(1+ts):n],y=y[(1+ts):n])) +
  geom_line(aes(y=value,color=variable),data=tmp) + theme_bw() + 
  ylab("Instantaneous Rate") +
  theme(legend.position="bottom")

grid.arrange(p1,p2,ncol=1)
```

In our meeting on Tuesday, I actually set the $\rho$ for $\mathcal{M}_4$ equal to 0.9, and now I change it to 0.7 so the mean of the negative binomial is the same as the lognormal for the transmission delays. It seems the reproduction-ish number is more similar to @Koyama_2021 by doing so.


\newpage

# County-level Covid Data

```{r}
data = read.csv("/Volumes/GoogleDrive/My Drive/Data/covid_county.csv")
data = data[data$state=="California",]
data$date = as.Date(data$date,format="%Y-%m-%d")
idx = (data$date >= start_date) & (data$date <= end_date)
data = data[idx,]
```

```{r}
m = 4.7
sd = 2.9
r = 2
rho = m/(m+r)
```

County-level Covid data from March 01, 2020 to March 01, 2021. The county-level data actually has a lot of zeros and even negative values. Therefor, I shifted the data as follows: $y \Leftarrow y - \min(y) + 1$, so that it has a minimum value of one. We need to consider preprocessing or different source of data if we want to use this data set.

In the following results, we can see some similarity between $\mathcal{M}_2$ and $\mathcal{M}_4$ for Santa Cruz and Monterey. Also, $\mathcal{M}_1$ has different behaviors compared to other models, probably some tuning is missing.

## Santa Cruz

```{r,out.width="50%"}
y = diff(data$cases[data$county=="Santa Cruz"])
x = data$date[data$county=="Santa Cruz"]
x = x[-1]
if (min(y)<0) {
  y = y - min(y) + 1
}
# y[y<0] = 0
n = length(y)
plot(x,y,type="l")
```

<!-- ### Koyama with Cauchy error -->

```{r,include=FALSE}
rate = hawke_ss2(y,rho=calc_rho(y),errtype="cauchy")
plot_hawkes_ss(y,rate$R,rate$itvl,rate$rate,
               x = x,
               plot_r=TRUE,plot_rate=FALSE)
```


<!-- ### Koyama with normal error -->

```{r,include=FALSE}
output1 = hawke_ss2(y,rho=calc_rho(y),errtype="normal")
plot_hawkes_ss(y,output1$R,output1$itvl,output1$rate,
               x = x,
               plot_r=TRUE,plot_rate=FALSE)
```

<!-- ### Koyama with exponential on reproduction number -->

```{r,include=FALSE}
output2 = lbe_pois_dlm(y,delta=0.88,L=30)
ts = 0
tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")
```


<!-- ### Pascal - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.9
output3 = lbe_poissonSolow(y[-1],log(y[-n]+.Machine$double.eps),rho,delta,m0,C0)

ts = 2

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output3$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output3$mt[1,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output3$mt[1,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output3$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")

plot(x,y,type="l")

# vest = diff(output3$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```


<!-- ### Pascal Identity Link - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.8
output4 = lbe_poissonSolowIdentity(y[-1],y[-n],rho,delta,m0,C0)

ts = 50

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output4$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[1,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[1,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")

plot(x,y,type="l")

# vest = diff(output3$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```


### Compare three different models

```{r,fig.nrow=2,fig.subcap=c("M1-KoyamaMax","M2-KoyamaExp","M3-PascalLog","M4-PascalEye"),out.width="25%",fig.cap="Santa Cruz: M2 uses a discount factor equal of 0.88; M3 uses rho=0.7 and a discount factor of 0.9; M4 uses rho=0.7 and a discount factor of 0.8."}
ts = 50

plot_hawkes_ss(y[(ts+1):n],
               output1$R[(ts+1):(n-1)],
               output1$itvl[,(ts+1):(n-1)],
               output1$rate[(ts+1):n],
               x = x[(ts+1):n],
               plot_r=TRUE,plot_rate=FALSE)

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("R")


tmp = data.frame(time=x[(ts+1):(n-1)],
                 beta=c(output3$mt[3,-c(1:(ts+1))]),
                 beta_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 beta_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))

ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=beta_lo,ymax=beta_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=beta),color="royalblue",na.rm=TRUE) +
  theme_bw() +
  xlab("Time") + ylab("Beta") + ylim(0.5,2)


tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")
```

```{r,fig.cap="Santa Cruz: M2 uses a discount factor equal of 0.88; M3 uses rho=0.7 and a discount factor of 0.9; M4 uses rho=0.7 and a discount factor of 0.8.",out.width="75%"}
ts = 50
tmp = data.frame(M1_KoyamaMax = output1$R[ts:(n-1)],
                 M2_KoyamaExp = exp(output2$mt_smooth[(1+ts):n,1]),
                 M3_PascalLog = output3$mt[3,(1+ts):(n)],
                 M4_PascalEye = output4$mt[3,(1+ts):(n)],
                 time = x[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p1 = ggplot(tmp,aes(x=time,y=value,color=variable)) +
  geom_line(show.legend=FALSE) + theme_bw() + 
  ylab("R") +
  theme(legend.position="none")

tmp = data.frame(M1_KoyamaMax = output1$rate[(1+ts):n],
                 M2_KoyamaExp = output2$rate[(1+ts):n],
                 M3_PascalLog = exp(output3$mt[1,(1+ts):n]),
                 M4_PascalEye = output4$mt[1,(1+ts):n],
                 time = x[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p2 = ggplot(tmp,aes(x=time)) +
  geom_point(aes(x=time,y=y),alpha=0.5,size=0.5,data=data.frame(time=x[(1+ts):n],y=y[(1+ts):n])) +
  geom_line(aes(y=value,color=variable),data=tmp) + theme_bw() + 
  ylab("Instantaneous Rate") +
  theme(legend.position="bottom")

grid.arrange(p1,p2,ncol=1)
```

\newpage

## Monterey

```{r,out.width="50%"}
y = diff(data$cases[data$county=="Monterey"])
x = data$date[data$county=="Monterey"]
x = x[-1]
if (min(y)<0) {
  y = y - min(y) + 1
}
n = length(y)
plot(x,y,type="l")
```

<!-- ### Koyama with Cauchy error -->

```{r,include=FALSE}
rate = hawke_ss2(y,rho=calc_rho(y),errtype="cauchy")
plot_hawkes_ss(y,rate$R,rate$itvl,rate$rate,
               x = x,
               plot_r=TRUE,plot_rate=FALSE)
```

<!-- ### Koyama with normal error -->

```{r,include=FALSE}
output1 = hawke_ss2(y,rho=calc_rho(y),errtype="normal")
plot_hawkes_ss(y,output1$R,output1$itvl,output1$rate,
               x = x,
               plot_r=TRUE,plot_rate=FALSE)
```


<!-- ### Koyama with exponential on reproduction number -->

```{r,include=FALSE}
output2 = lbe_pois_dlm(y,delta=0.88,L=30)
ts = 0
tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")
```

<!-- ### Pascal Exponential Link - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.8
output3 = lbe_poissonSolow(y[-1],log(y[-n]+.Machine$double.eps),rho,delta,m0,C0)

ts = 50

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output3$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output3$mt[1,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output3$mt[1,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output3$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")

plot(x,y,type="l")

# vest = diff(output3$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```


<!-- ### Pascal Identity Link - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.8
output4 = lbe_poissonSolowIdentity(y[-1],y[-n],rho,delta,m0,C0)

ts = 50

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output4$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[1,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[1,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")

plot(x,y,type="l")

# vest = diff(output3$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```


### Compare three different models

```{r,fig.nrow=2,fig.subcap=c("M1-KoyamaMax","M2-KoyamaExp","M3-PascalLog","M4-PascalEye"),out.width="25%",fig.cap="Monterey: M2 uses a discount factor equal of 0.88; M3 uses rho=0.7 and a discount factor of 0.8; M4 uses rho=0.7 and a discount factor of 0.8."}
ts = 50

plot_hawkes_ss(y[(ts+1):n],
               output1$R[(ts+1):(n-1)],
               output1$itvl[,(ts+1):(n-1)],
               output1$rate[(ts+1):n],
               x = x[(ts+1):n],
               plot_r=TRUE,plot_rate=FALSE)

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("R")


tmp = data.frame(time=x[(ts+1):(n-1)],
                 beta=c(output3$mt[3,-c(1:(ts+1))]),
                 beta_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 beta_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))

ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=beta_lo,ymax=beta_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=beta),color="royalblue",na.rm=TRUE) +
  theme_bw() +
  xlab("Time") + ylab("Beta") + ylim(0.5,2)


tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")
```

```{r,fig.cap="Monterey: M2 uses a discount factor equal of 0.88; M3 uses rho=0.7 and a discount factor of 0.8; M4 uses rho=0.7 and a discount factor of 0.8.",out.width="75%"}
ts = 50
tmp = data.frame(M1_KoyamaMax = output1$R[ts:(n-1)],
                 M2_KoyamaExp = exp(output2$mt_smooth[(1+ts):n,1]),
                 M3_PascalLog = output3$mt[3,(1+ts):(n)],
                 M4_PascalEye = output4$mt[3,(1+ts):(n)],
                 time = x[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p1 = ggplot(tmp,aes(x=time,y=value,color=variable)) +
  geom_line(show.legend=FALSE) + theme_bw() + 
  ylab("R") +
  theme(legend.position="none")

tmp = data.frame(M1_KoyamaMax = output1$rate[(1+ts):n],
                 M2_KoyamaExp = output2$rate[(1+ts):n],
                 M3_PascalLog = exp(output3$mt[1,(1+ts):n]),
                 M4_PascalEye = output4$mt[1,(1+ts):n],
                 time = x[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p2 = ggplot(tmp,aes(x=time)) +
  geom_point(aes(x=time,y=y),alpha=0.5,size=0.5,data=data.frame(time=x[(1+ts):n],y=y[(1+ts):n])) +
  geom_line(aes(y=value,color=variable),data=tmp) + theme_bw() + 
  ylab("Instantaneous Rate") +
  theme(legend.position="bottom")

grid.arrange(p1,p2,ncol=1)
```


## Santa Clara

```{r,out.width="50%"}
y = diff(data$cases[data$county=="Santa Clara"])
x = data$date[data$county=="Santa Clara"]
x = x[-1]
if (min(y)<0) {
  y = y - min(y) + 1
}
n = length(y)
plot(x,y,type="l")
```

<!-- ### Koyama with Cauchy error -->

```{r,include=FALSE}
rate = hawke_ss2(y,rho=calc_rho(y),errtype="cauchy")
plot_hawkes_ss(y,rate$R,rate$itvl,rate$rate,
               x = x,
               plot_r=TRUE,plot_rate=FALSE)
```

<!-- ### Koyama with normal error -->

```{r,include=FALSE}
output1 = hawke_ss2(y,rho=calc_rho(y),errtype="normal")
plot_hawkes_ss(y,output1$R,output1$itvl,output1$rate,
               x = x,
               plot_r=TRUE,plot_rate=FALSE)
```


<!-- ### Koyama with exponential on reproduction number -->

```{r,include=FALSE}
output2 = lbe_pois_dlm(y,delta=0.95,L=30)
ts = 0
tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")
```

<!-- ### Pascal Exponential Link - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.8
output3 = lbe_poissonSolow(y[-1],log(y[-n]+.Machine$double.eps),rho,delta,m0,C0)

ts = 50

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output3$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output3$mt[1,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output3$mt[1,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[1,1,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output3$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")

plot(x,y,type="l")

# vest = diff(output3$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```


<!-- ### Pascal Identity Link - LBE -->

```{r,include=FALSE}
rho = 0.7
delta = 0.8
output4 = lbe_poissonSolowIdentity(y[-1],y[-n],rho,delta,m0,C0)

ts = 50

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output4$mt[1,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[1,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[1,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[1,1,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("State")

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")

plot(x,y,type="l")

# vest = diff(output3$mt[3,-c(1:(ts+1))])
# plot(vest,type="l",col="royalblue")
```


### Compare three different models

```{r,fig.nrow=2,fig.subcap=c("M1-KoyamaMax","M2-KoyamaExp","M3-PascalLog","M4-PascalEye"),out.width="25%",fig.cap="Santa Clara: M2 uses a discount factor equal of 0.95; M3 uses rho=0.7 and a discount factor of 0.9; M4 uses rho=0.7 and a discount factor of 0.8."}
ts = 50

plot_hawkes_ss(y[(ts+1):n],
               output1$R[(ts+1):(n-1)],
               output1$itvl[,(ts+1):(n-1)],
               output1$rate[(ts+1):n],
               x = x[(ts+1):n],
               plot_r=TRUE,plot_rate=FALSE)

tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=exp(c(output2$mt_smooth[-c(1:(ts+1)),1])),
                 mt_lo=exp(c(output2$mt[-c(1:(ts+1)),1])-2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))),
                 mt_hi=exp(c(output2$mt[-c(1:(ts+1)),1])+2*sqrt(c(output2$Ct[-c(1:(ts+1)),1,1]))))

ggplot(tmp,aes(x=time)) +
  # geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
  #             fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("R")


tmp = data.frame(time=x[(ts+1):(n-1)],
                 beta=c(output3$mt[3,-c(1:(ts+1))]),
                 beta_lo=c(output3$mt[3,-c(1:(ts+1))])-2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])),
                 beta_hi=c(output3$mt[3,-c(1:(ts+1))])+2*sqrt(c(output3$Ct[3,3,-c(1:(ts+1))])))

ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=beta_lo,ymax=beta_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=beta),color="royalblue",na.rm=TRUE) +
  theme_bw() +
  xlab("Time") + ylab("Beta") + ylim(0.5,2)


tmp = data.frame(time=x[(ts+1):(n-1)],
                 mt=c(output4$mt[3,-c(1:(ts+1))]),
                 mt_lo=c(output4$mt[3,-c(1:(ts+1))])-2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])),
                 mt_hi=c(output4$mt[3,-c(1:(ts+1))])+2*sqrt(c(output4$Ct[3,3,-c(1:(ts+1))])))
ggplot(tmp,aes(x=time)) +
  geom_ribbon(aes(ymin=mt_lo,ymax=mt_hi),
              fill="royalblue",alpha=0.2) +
  geom_line(aes(y=mt),color="royalblue") +
  theme_bw() +
  xlab("Time") + ylab("Beta")
```

```{r,fig.cap="Santa Clara: M2 uses a discount factor equal of 0.95; M3 uses rho=0.7 and a discount factor of 0.9; M4 uses rho=0.7 and a discount factor of 0.8.",out.width="75%"}
ts = 50
tmp = data.frame(M1_KoyamaMax = output1$R[ts:(n-1)],
                 M2_KoyamaExp = exp(output2$mt_smooth[(1+ts):n,1]),
                 M3_PascalLog = output3$mt[3,(1+ts):(n)],
                 M4_PascalEye = output4$mt[3,(1+ts):(n)],
                 time = x[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p1 = ggplot(tmp,aes(x=time,y=value,color=variable)) +
  geom_line(show.legend=FALSE) + theme_bw() + 
  ylab("R") +
  theme(legend.position="none")

tmp = data.frame(M1_KoyamaMax = output1$rate[(1+ts):n],
                 M2_KoyamaExp = output2$rate[(1+ts):n],
                 M3_PascalLog = exp(output3$mt[1,(1+ts):n]),
                 M4_PascalEye = output4$mt[1,(1+ts):n],
                 time = x[(1+ts):n])
tmp = reshape2::melt(tmp,id.vars="time")
p2 = ggplot(tmp,aes(x=time)) +
  geom_point(aes(x=time,y=y),alpha=0.5,size=0.5,data=data.frame(time=x[(1+ts):n],y=y[(1+ts):n])) +
  geom_line(aes(y=value,color=variable),data=tmp) + theme_bw() + 
  ylab("Instantaneous Rate") +
  theme(legend.position="bottom")

grid.arrange(p1,p2,ncol=1)
```

\newpage

# References

<div id="refs"></div>


